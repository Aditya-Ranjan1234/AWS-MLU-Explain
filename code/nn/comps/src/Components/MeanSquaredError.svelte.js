import{SvelteComponent as e,init as n,safe_not_equal as t,element as a,space as i,text as s,create_component as r,attr as o,insert as l,append as d,set_input_value as u,mount_component as c,action_destroyer as h,listen as m,set_data as f,transition_in as p,transition_out as g,detach as w,destroy_component as b,run_all as v,component_subscribe as y,HtmlTag as x,to_number as M,binding_callbacks as $}from"../../node_modules/svelte/internal/index.mjs.js";import{mseBias as q,mseWeight as S,mseError as E,RSS as _,TSS as T,rSquared as k}from"../store.js";import R from"../katexify.js";import C from"./MSEScatterplot.svelte.js";import{tooltip as j}from"../tooltip.js";import{format as A}from"../../node_modules/d3-format/src/defaultLocale.js";function L(e){let n,t,y,M,$,q,S,E,_,T,k,A,L,z,H,I,F,D,W,Y,B,G,J,K,N,O,P,Q,U,V,X,Z,ee,ne,te,ae,ie,se,re,oe,le,de,ue,ce,he,me,fe,pe,ge,we,be,ve,ye,xe,Me,$e,qe,Se,Ee,_e,Te,ke,Re,Ce,je,Ae,Le,ze,He,Ie,Fe,De,We,Ye,Be,Ge,Je,Ke,Ne,Oe,Pe,Qe,Ue,Ve,Xe,Ze,en,nn,tn,an,sn,rn,on,ln,dn,un,cn,hn,mn,fn=R("\\begin{aligned} MSE = \\frac{1}{n} \\Sigma^{n}_{i=1}(y_i - \\hat{y_i})^2 \\end{aligned}",!0)+"",pn=R("y",!1)+"",gn=R("x",!1)+"",wn=R("\\begin{aligned} R^2 = 1 - \\frac{\\Sigma^{n}_{i=1}(y_i - \\hat{y_i})^2 }{\\Sigma^{n}_{i=1}(y_i - \\bar{y})^2 }  \\end{aligned}",!0)+"",bn=R("\\hat{\\beta_0}",!1)+"",vn=e[7](e[1])+"",yn=R("\\hat{\\beta_1}",!1)+"",xn=e[7](e[2])+"",Mn=R(`\\hat{y} = ${e[7](e[2])}x${e[1]<0?"":"+"}${e[7](e[1])}`)+"",$n=R(`\\begin{aligned} MSE = \\frac{1}{n} \\Sigma^{n}_{i=1}(y - (${e[7](e[2])}x${e[1]<0?"":"+"}${e[7](e[1])}))^2 = ${e[7](e[3])} \\end{aligned}`)+"",qn=R(`\\begin{aligned} R^2 = 1 - \\frac{${e[7](e[4])}}{${e[7](e[5])}}  = ${e[7](e[6])} \\end{aligned}`)+"";return nn=new C({props:{}}),e[11](nn),{c(){n=a("section"),t=a("h1"),t.textContent="Model Evaluation",y=i(),M=a("p"),$=a("br"),q=s("\n    To train an accurate linear regression model, we need a way to quantify how good\n    (or bad) our model performs. In machine learning, we call such performance-measuring\n    functions "),S=a("i"),S.textContent="loss functions",E=s(". Several popular loss functions exist for\n    regression problems."),_=a("sup"),T=a("span"),T.textContent="[ℹ]",k=s("\n    To measure our model's performance, we'll use one of the most popular: mean-squared\n    error (MSE).\n    "),A=a("br"),L=a("br"),z=i(),H=a("span"),H.textContent="Mean-Squared Error (MSE)",I=i(),F=a("br"),D=s("\n    MSE quantifies how close a predicted value is to the true value, so we'll use\n    it to quantify how close a regression line is to a set of points. MSE works by\n    squaring the distance between each data point and the regression line (the red\n    residuals in the graphs above), summing the squared values, and then dividing\n    by the number of data points: "),W=new x(!1),Y=s("\n    The name is quite literal: take the mean of the squared errors. The squaring\n    of errors prevents negative and positive terms from canceling out in the sum,"),B=a("sup"),G=a("span"),G.textContent="[ℹ]",J=s("\n    and gives more weight to points further from the regression line, punishing outliers.\n    In practice, we'll fit our regression model to a set training data, and evaluate\n    it's performance using MSE on the test dataset.\n    \n    "),K=a("br"),N=a("br"),O=i(),P=a("span"),P.textContent="R-Squared",Q=i(),U=a("br"),V=s("\n    Regression models may also be evaluated with the so-called\n    "),X=a("i"),X.textContent="goodness of fit",Z=s("\n    measures, which summarize how well a model fits a set of data. The most popular\n    goodness of fit measure for linear regression is r-squared, a metric that represents\n    the percentage of the variance in "),ee=new x(!1),ne=s(" explained by our\n    features "),te=new x(!1),ae=s("."),ie=a("sup"),se=a("span"),se.textContent="[ℹ]",re=s("\n    More specifically, r-squared measures the percentage of variance explained normalized\n    against the baseline variance of our model (which is just the variance of the\n    mean):\n    "),oe=new x(!1),le=s("\n    The highest possible value for r-squared is 1, representing a model that captures\n    100% of the variance. A negative r-squared means that our model is doing worse\n    (capturing less variance) than a flat line through mean of our data would.\n\n    "),de=a("br"),ue=a("br"),ce=s("To build intuition for yourself, try changing the weight and\n    bias terms below to see how the MSE and r-squared change across different\n    model fits:"),he=i(),me=a("br"),fe=a("br"),pe=i(),ge=a("div"),we=a("div"),be=a("div"),ve=a("button"),ve.textContent="Shuffle Data",ye=i(),xe=a("div"),Me=a("div"),$e=a("p"),qe=s("Bias ("),Se=new x(!1),Ee=s("): "),_e=s(vn),Te=i(),ke=a("input"),Re=i(),Ce=a("div"),je=a("div"),Ae=a("p"),Le=s("Weight ("),ze=new x(!1),He=s("): "),Ie=s(xn),Fe=i(),De=a("input"),We=i(),Ye=a("br"),Be=i(),Ge=a("div"),Je=s("For our model: "),Ke=new x(!1),Ne=i(),Oe=a("br"),Pe=i(),Qe=a("div"),Ue=i(),Ve=a("div"),Xe=i(),Ze=a("div"),en=a("div"),r(nn.$$.fragment),tn=i(),an=a("br"),sn=a("br"),rn=i(),on=a("br"),ln=a("br"),dn=i(),un=a("p"),un.innerHTML='You will often see R-Squared referenced in statistical contexts as a way to\n    assess model fit.\n    <br/><br/> \n    <span class="bold">Selecting An Evaluation Metric</span><br/>\n    Many methods exist for evaluating regression models, each with different concerns\n    around interpretability, theory, and usability. The evaluation metric should\n    reflect whatever it is you actually care about when making predictions. For example,\n    when we use MSE, we are implicitly saying that we think the cost of our prediction\n    error should reflect the quadratic (squared) distance between what we predicted\n    and what is correct. This may work well if we want to punish outliers or if our\n    data is minimized by the mean, but this comes at the cost of interpretability:\n    we output our error in squared units (though this may be fixed with\n    <a href="https://en.wikipedia.org/wiki/Root-mean-square_deviation">RMSE</a>). If instead we wanted our error to reflect the linear distance between\n    what we predicted and what is correct, or we wanted our data minimized by\n    the median, we could try something like Mean Abosulte Error (<a href="https://en.wikipedia.org/wiki/Mean_absolute_error">MAE</a>). Whatever the case, you should be thinking of your evaluation metric as\n    part of your modeling process, and select the best metric based on the\n    specific concerns of your use-case.',o(t,"class","body-header"),o(T,"class","info-tooltip"),o(T,"title","You can actually use whatever you want, as long as minimizing it achieves your goal."),o(H,"class","bold"),W.a=Y,o(G,"class","info-tooltip"),o(G,"title","There is nothing stopping us from using a different norm instead, so as \n        long as the positive and negative values cancel out. For example,\n        if we took the absolute value of our errors instead of the square, we'd have the\n        popular loss-function Mean-Absolute Error (MAE)."),o(P,"class","bold"),ee.a=ne,te.a=ae,o(se,"class","info-tooltip"),o(se,"title","Intuitively, an ideal model would explain all of the variation in the data for all inputs."),oe.a=le,o(M,"class","body-text"),o(ve,"class","svelte-1xwiimh"),o(be,"id","buttons-container"),o(be,"class","svelte-1xwiimh"),Se.a=Ee,o(ke,"type","range"),o(ke,"min","-2"),o(ke,"step","0.5"),o(ke,"max","16"),o(ke,"class","slider"),o(ke,"id","myRange"),o(Me,"class","input-container svelte-1xwiimh"),o(xe,"id","bias-slider"),ze.a=He,o(De,"type","range"),o(De,"min","-1.5"),o(De,"max","6"),o(De,"step",".01"),o(De,"class","slider"),o(De,"id","myRange"),o(je,"class","input-container svelte-1xwiimh"),o(Ce,"id","weight-slider"),Ke.a=null,o(Ge,"id","equation-math"),o(Qe,"id","equation-math"),o(Ve,"id","equation-math"),o(we,"id","equations-container"),o(we,"class","svelte-1xwiimh"),o(en,"id","mse-chart-regression"),o(en,"class","svelte-1xwiimh"),o(Ze,"id","charts-container"),o(Ze,"class","svelte-1xwiimh"),o(ge,"id","mse-container"),o(ge,"class","svelte-1xwiimh"),o(un,"class","body-text")},m(a,i){l(a,n,i),d(n,t),d(n,y),d(n,M),d(M,$),d(M,q),d(M,S),d(M,E),d(M,_),d(_,T),d(M,k),d(M,A),d(M,L),d(M,z),d(M,H),d(M,I),d(M,F),d(M,D),W.m(fn,M),d(M,Y),d(M,B),d(B,G),d(M,J),d(M,K),d(M,N),d(M,O),d(M,P),d(M,Q),d(M,U),d(M,V),d(M,X),d(M,Z),ee.m(pn,M),d(M,ne),te.m(gn,M),d(M,ae),d(M,ie),d(ie,se),d(M,re),oe.m(wn,M),d(M,le),d(M,de),d(M,ue),d(M,ce),d(n,he),d(n,me),d(n,fe),d(n,pe),d(n,ge),d(ge,we),d(we,be),d(be,ve),d(we,ye),d(we,xe),d(xe,Me),d(Me,$e),d($e,qe),Se.m(bn,$e),d($e,Ee),d($e,_e),d(Me,Te),d(Me,ke),u(ke,e[1]),d(we,Re),d(we,Ce),d(Ce,je),d(je,Ae),d(Ae,Le),ze.m(yn,Ae),d(Ae,He),d(Ae,Ie),d(je,Fe),d(je,De),u(De,e[2]),d(we,We),d(we,Ye),d(we,Be),d(we,Ge),d(Ge,Je),Ke.m(Mn,Ge),d(we,Ne),d(we,Oe),d(we,Pe),d(we,Qe),Qe.innerHTML=$n,d(we,Ue),d(we,Ve),Ve.innerHTML=qn,d(ge,Xe),d(ge,Ze),d(Ze,en),c(nn,en,null),d(n,tn),d(n,an),d(n,sn),d(n,rn),d(n,on),d(n,ln),d(n,dn),d(n,un),cn=!0,hn||(mn=[h(j.call(null,T)),h(j.call(null,G)),h(j.call(null,se)),m(ve,"click",e[8]),m(ke,"change",e[9]),m(ke,"input",e[9]),m(De,"change",e[10]),m(De,"input",e[10])],hn=!0)},p(e,[n]){(!cn||2&n)&&vn!==(vn=e[7](e[1])+"")&&f(_e,vn),2&n&&u(ke,e[1]),(!cn||4&n)&&xn!==(xn=e[7](e[2])+"")&&f(Ie,xn),4&n&&u(De,e[2]),(!cn||6&n)&&Mn!==(Mn=R(`\\hat{y} = ${e[7](e[2])}x${e[1]<0?"":"+"}${e[7](e[1])}`)+"")&&Ke.p(Mn),(!cn||14&n)&&$n!==($n=R(`\\begin{aligned} MSE = \\frac{1}{n} \\Sigma^{n}_{i=1}(y - (${e[7](e[2])}x${e[1]<0?"":"+"}${e[7](e[1])}))^2 = ${e[7](e[3])} \\end{aligned}`)+"")&&(Qe.innerHTML=$n),(!cn||112&n)&&qn!==(qn=R(`\\begin{aligned} R^2 = 1 - \\frac{${e[7](e[4])}}{${e[7](e[5])}}  = ${e[7](e[6])} \\end{aligned}`)+"")&&(Ve.innerHTML=qn);nn.$set({})},i(e){cn||(p(nn.$$.fragment,e),cn=!0)},o(e){g(nn.$$.fragment,e),cn=!1},d(t){t&&w(n),e[11](null),b(nn),hn=!1,v(mn)}}}function z(e,n,t){let a,i,s,r,o,l,d;y(e,q,(e=>t(1,a=e))),y(e,S,(e=>t(2,i=e))),y(e,E,(e=>t(3,s=e))),y(e,_,(e=>t(4,r=e))),y(e,T,(e=>t(5,o=e))),y(e,k,(e=>t(6,l=e)));const u=A(".2f");return[d,a,i,s,r,o,l,u,()=>d.shuffleData(),function(){a=M(this.value),q.set(a)},function(){i=M(this.value),S.set(i)},function(e){$[e?"unshift":"push"]((()=>{d=e,t(0,d)}))}]}class H extends e{constructor(e){super(),n(this,e,z,L,t,{})}}export{H as default};
